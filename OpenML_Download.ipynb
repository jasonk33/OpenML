{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from requests import get\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from os import listdir\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autotime\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Workflow:\n",
    "- Only look at data from supervised classification tasks from OpenML\n",
    "- Get all data relating to when a sklearn primitive is used\n",
    "   - Looking at all supervised classification tasks, get all flows\n",
    "   - Only look at tasks where a sklearn flow is used\n",
    "   - Get run information for sklearn runs for those tasks\n",
    "   - Get dataset information for those tasks\n",
    "   - Get accuracy information for those runs\n",
    "- Get all data relating to when a weka primitive is used\n",
    "   - Only use tasks where sklearn flow is used to keep dataset consistent\n",
    "   - Only look at tasks where a sklearn flow is used\n",
    "   - Get run information for sklearn runs for those tasks\n",
    "   - Get accuracy information for those runs\n",
    "- Get dataset qualities and features\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.58 ms\n"
     ]
    }
   ],
   "source": [
    "# API Key for downloading data from OpenML\n",
    "api_key = \"1dbab546719d8085308a5bfde18381d7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.04 ms\n"
     ]
    }
   ],
   "source": [
    "# Download all the flows from OpenML and save all flow names by there id\n",
    "all_flows = get(\"https://www.openml.org/api/v1/json/flow/list?api_key=\" + api_key).json()\n",
    "flow_id_names = {}\n",
    "for flow in all_flows['flows']['flow']:\n",
    "    flow_id_names[flow['id']] = flow['name']\n",
    "    \n",
    "# with open('OpenML_Data/flow_id_names.json', 'w') as outfile:\n",
    "#     json.dump(flow_id_names, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.38 s\n"
     ]
    }
   ],
   "source": [
    "# Download all the tasks from OpenML and get all task ids for superivsed classification\n",
    "all_tasks = get(\"https://www.openml.org/api/v1/json/task/list?api_key=\" + api_key).json()\n",
    "supervised_classification_task_ids = []\n",
    "for task in all_tasks['tasks']['task']:\n",
    "    if task['task_type'] == 'Supervised Classification':\n",
    "        supervised_classification_task_ids.append(task['task_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.68 ms\n"
     ]
    }
   ],
   "source": [
    "# Get all runs for all supervised classification tasks and get all unique flow ids used\n",
    "supervised_classification_flow_ids = []\n",
    "for task_id in supervised_classification_task_ids:\n",
    "    try:\n",
    "        runs = get(\"https://www.openml.org/api/v1/json/run/list/task/\" + str(task_id) + \"/limit/10000?api_key=\" + api_key)\n",
    "        runs = runs.json()\n",
    "    except:\n",
    "        runs = json.loads(runs.text.replace('\\n', ''))\n",
    "    if 'error' not in runs:\n",
    "        for run in runs['runs']['run']:\n",
    "            supervised_classification_flow_ids.append(run['flow_id'])\n",
    "        supervised_classification_flow_ids = list(set(supervised_classification_flow_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the flow descriptions for all extracted flow ids\n",
    "supervised_classification_flow_descriptions = []\n",
    "for flow in supervised_classification_flow_ids[1:]:\n",
    "    flow_description = get(\"https://www.openml.org/api/v1/json/flow/\" + str(flow) + \"?api_key=\" + api_key).json()\n",
    "    if 'error' not in flow_description:\n",
    "        supervised_classification_flow_descriptions.append(flow_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sklearn Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6.08 ms\n"
     ]
    }
   ],
   "source": [
    "# Get all the flow ids for sklearn flows\n",
    "sklearn_flows = []\n",
    "for flow in supervised_classification_flow_descriptions:\n",
    "    if flow['flow']['name'][0:7] == 'sklearn':\n",
    "        sklearn_flows.append(flow['flow']['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all flow descriptions for sklearn flows and runs for each sklearn flow\n",
    "num_flows = len(sklearn_flows)\n",
    "sklearn_flow_descriptions = {}\n",
    "sklearn_runs_info = {}\n",
    "for flow in sklearn_flows:\n",
    "    runs_info = get(\"https://www.openml.org/api/v1/json/run/list/flow/\" + flow + \"?api_key=\" + api_key).json()\n",
    "    flow_description = get(\"https://www.openml.org/api/v1/json/flow/\" + flow + \"?api_key=\" + api_key).json()\n",
    "    if ('error' not in runs_info) and ('error' not in flow_description):\n",
    "        sklearn_runs_info[flow] = runs_info\n",
    "        sklearn_flow_descriptions[flow] = flow_description\n",
    "        \n",
    "# with open('OpenML_Data/sklearn_flow_descriptions.json', 'w') as outfile:\n",
    "#     json.dump(sklearn_flow_descriptions, outfile)\n",
    "# with open('OpenML_Data/sklearn_runs_info.json', 'w') as outfile:\n",
    "#     json.dump(sklearn_runs_info, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 58.8 ms\n"
     ]
    }
   ],
   "source": [
    "# Get all unique task and setup ids for sklearn runs\n",
    "sklearn_task_ids = []\n",
    "sklearn_setup_ids = []\n",
    "for flow,runs in sklearn_runs_info.items():\n",
    "    for run in runs['runs']['run']:\n",
    "        sklearn_task_ids.append(run['task_id'])\n",
    "        sklearn_setup_ids.append(run['setup_id'])\n",
    "sklearn_task_ids = list(set(sklearn_task_ids))\n",
    "sklearn_setup_ids = list(set(sklearn_setup_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get task descriptions for all tasks with any runs that use a sklearn flow\n",
    "sklearn_task_descriptions = {}\n",
    "for task_id in sklearn_task_ids:\n",
    "    task_description = get(\"https://www.openml.org/api/v1/json/task/\" + str(task_id) + \"?api_key=\" + api_key).json()\n",
    "    sklearn_task_descriptions[task_id] = task_description\n",
    "    \n",
    "# with open('OpenML_Data/sklearn_task_descriptions.json', 'w') as outfile:\n",
    "#     json.dump(sklearn_task_descriptions, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the setup descriptions for all sklearn setup ids\n",
    "sklearn_setup_descriptions = {}\n",
    "for setup_id in sklearn_setup_ids:\n",
    "    setup_description = get(\"https://www.openml.org/api/v1/json/setup/\" + str(setup_id) + \"?api_key=\" + api_key).json()\n",
    "    sklearn_setup_descriptions[setup_id] = setup_description\n",
    "    \n",
    "# with open('OpenML_Data/sklearn_setup_descriptions.json', 'w') as outfile:\n",
    "#     json.dump(sklearn_setup_descriptions, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.6 ms\n"
     ]
    }
   ],
   "source": [
    "# Get the dataset ids for all sklearn tasks\n",
    "sklearn_data_set_ids = []\n",
    "for task_id,task_description in sklearn_task_descriptions.items():\n",
    "    data_set_id = task_description['task']['input'][0]['data_set']['data_set_id']\n",
    "    sklearn_data_set_ids.append(data_set_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dataset descriptions for all sklearn datasets\n",
    "sklearn_data_set_descriptions = {}\n",
    "for data_set_id in sklearn_data_set_ids:\n",
    "    data_set_description = get(\"https://www.openml.org/api/v1/json/data/\" + str(data_set_id) + \"?api_key=\" + api_key).json()\n",
    "    sklearn_data_set_descriptions[data_set_id] = data_set_description\n",
    "    \n",
    "# with open('OpenML_Data/sklearn_data_set_descriptions.json', 'w') as outfile:\n",
    "#     json.dump(sklearn_data_set_descriptions, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the run descriptions for all sklearn runs (takes very long)\n",
    "sklearn_run_descriptions = {}\n",
    "for flow,runs in sklearn_runs_info.items():\n",
    "    for run in runs['runs']['run']:\n",
    "        run_id = run['run_id']\n",
    "        run_description = get(\"https://www.openml.org/api/v1/json/run/\" + str(run_id) + \"?api_key=\" + api_key).json()\n",
    "        sklearn_run_descriptions[run_id] = run_description\n",
    "        \n",
    "# with open('OpenML_Data/sklearn_run_descriptions.json', 'w') as outfile:\n",
    "#     json.dump(sklearn_run_descriptions, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.08 s\n"
     ]
    }
   ],
   "source": [
    "# Get all sklearn primitives for each run\n",
    "flows_per_run = {}\n",
    "for run_id,run_description in sklearn_run_descriptions.items():\n",
    "    flow_id = run_description['run']['flow_id']\n",
    "    flow_names = []\n",
    "    flow_description = sklearn_flow_descriptions[flow_id]['flow']\n",
    "    if 'component' in flow_description:\n",
    "        compnents = flow_description['component']\n",
    "        if type(compnents) == dict:\n",
    "            flow_names.append(compnents['flow']['class_name'])\n",
    "            flows_per_run[run_id] = flow_names\n",
    "        else:\n",
    "            for flow in flow_description['component']:\n",
    "                flow_names.append(flow['flow']['class_name'])\n",
    "            flows_per_run[run_id] = flow_names\n",
    "    else:\n",
    "        flows_per_run[run_id] = [flow_description['name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 36.1 ms\n"
     ]
    }
   ],
   "source": [
    "# Get the number of times each sklearn flow is run\n",
    "flow_names = {}\n",
    "for run,flows in flows_per_run.items():\n",
    "    for flow in flows:\n",
    "        if flow in flow_names:\n",
    "            flow_names[flow] += 1\n",
    "        else:\n",
    "            flow_names[flow] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 36.7 ms\n"
     ]
    }
   ],
   "source": [
    "# Load the accuracy of all runs for all sklearn tasks (computed on brown ccv)\n",
    "task_accuracies = {}\n",
    "for file in listdir(\"OpenML_Data/accuracy_results/results\")[1:]:\n",
    "    with open('OpenML_Data/accuracy_results/results/' + file) as data_file:\n",
    "        acc = json.load(data_file)\n",
    "    task_accuracies.update(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.64 s\n"
     ]
    }
   ],
   "source": [
    "# Get the adjusted average accuracy (flow accuracy minus mean task accuracy) for all sklearn flows\n",
    "sklearn_flow_accuracies = {}\n",
    "for run_id, run_description in sklearn_run_descriptions.items():\n",
    "    for metric in run_description['run']['output_data']['evaluation']:\n",
    "        if metric['name'] == 'predictive_accuracy':\n",
    "            accuracy = float(metric['value'])\n",
    "            try:\n",
    "                avg_task_acc = task_accuracies[run_description['run']['task_id']]\n",
    "                adjusted_accuracy = (accuracy - avg_task_acc)/avg_task_acc\n",
    "                for flow in flows_per_run[run_id]:\n",
    "                    if flow in sklearn_flow_accuracies:\n",
    "                        sklearn_flow_accuracies[flow].append(adjusted_accuracy)\n",
    "                    else:\n",
    "                        sklearn_flow_accuracies[flow] = [adjusted_accuracy]\n",
    "                break\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "# with open('OpenML_Data/sklearn_flow_accuracies.json', 'w') as outfile:\n",
    "#     json.dump(sklearn_flow_accuracies, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 595 ms\n"
     ]
    }
   ],
   "source": [
    "# Create dataframe of average sklearn flow adjusted accuracies\n",
    "mean_flow_accuracies = pd.DataFrame(columns=['Name', 'Adj_Accuracy', 'Count', 'sd'])\n",
    "for flow,accuracies in sklearn_flow_accuracies.items():\n",
    "    mean_flow_accuracies = mean_flow_accuracies.append(pd.DataFrame([[flow,np.asarray(accuracies).astype(np.float).mean(), len(accuracies), np.asarray(accuracies).astype(np.float).std()]], columns=['Name', 'Adj_Accuracy', 'Count', 'sd']))\n",
    "mean_flow_accuracies = mean_flow_accuracies[mean_flow_accuracies['Count'] >= 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformatting flow accuracies for plotting\n",
    "flow_accuracies_df = pd.DataFrame(columns=['Name', 'Adj_Accuracy'])\n",
    "for flow,accuracies in sklearn_flow_accuracies.items():\n",
    "    for accuracy in accuracies:\n",
    "        flow_accuracies_df = flow_accuracies_df.append(pd.DataFrame([[flow,accuracy]], columns=['Name', 'Adj_Accuracy']))\n",
    "flow_accuracies_df = flow_accuracies_df[flow_accuracies_df.groupby('Name').Adj_Accuracy.transform(len) > 10]\n",
    "\n",
    "# flow_accuracies_df.to_csv(\"OpenML_Data/sklearn_flow_accuracies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 22.8 s\n"
     ]
    }
   ],
   "source": [
    "# Load data \n",
    "with open('OpenML_Data/sklearn_run_descriptions.json') as data_file:\n",
    "    sklearn_run_descriptions = json.load(data_file)\n",
    "with open('OpenML_Data/flow_descriptions.json') as data_file:\n",
    "    flow_descriptions = json.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Weka Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 9.91 ms\n"
     ]
    }
   ],
   "source": [
    "# Get all flows that are weka (java)\n",
    "weka_flows = []\n",
    "for flow in flow_descriptions:\n",
    "    if flow['flow']['name'][0:4] == 'weka':\n",
    "        weka_flows.append(flow['flow']['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all flow descriptions for weka flows and runs for each weka flow (23 minutes)\n",
    "weka_flow_descriptions = {}\n",
    "weka_runs_info = {}\n",
    "for flow in weka_flows:\n",
    "    runs_info = get(\"https://www.openml.org/api/v1/json/run/list/flow/\" + flow + \"?api_key=\" + api_key).json()\n",
    "    flow_description = get(\"https://www.openml.org/api/v1/json/flow/\" + flow + \"?api_key=\" + api_key).json()\n",
    "    if ('error' not in runs_info) and ('error' not in flow_description):\n",
    "        weka_runs_info[flow] = runs_info\n",
    "        weka_flow_descriptions[flow] = flow_description\n",
    "        \n",
    "# with open('OpenML_Data/weka_flow_descriptions.json', 'w') as outfile:\n",
    "#     json.dump(weka_flow_descriptions, outfile)\n",
    "# with open('OpenML_Data/weka_runs_info.json', 'w') as outfile:\n",
    "#     json.dump(weka_runs_info, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 210 ms\n"
     ]
    }
   ],
   "source": [
    "# Get all unique task and setup ids for weka runs\n",
    "weka_task_ids = []\n",
    "weka_setup_ids = []\n",
    "for flow,runs in weka_runs_info.items():\n",
    "    for run in runs['runs']['run']:\n",
    "        weka_task_ids.append(run['task_id'])\n",
    "        weka_setup_ids.append(run['setup_id'])\n",
    "weka_task_ids = list(set(weka_task_ids))\n",
    "weka_setup_ids = list(set(weka_setup_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get the setup descriptions for all weka setup ids (55 minutes)\n",
    "weka_setup_descriptions = {}\n",
    "for setup_id in weka_setup_ids:\n",
    "    setup_description = get(\"https://www.openml.org/api/v1/json/setup/\" + str(setup_id) + \"?api_key=\" + api_key).json()\n",
    "    weka_setup_descriptions[setup_id] = setup_description\n",
    "    \n",
    "# with open('OpenML_Data/weka_setup_descriptions.json', 'w') as outfile:\n",
    "#     json.dump(weka_setup_descriptions, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.61 ms\n"
     ]
    }
   ],
   "source": [
    "# Get all task ids for sklearn tasks\n",
    "with open('OpenML_Data/sklearn_task_descriptions.json') as data_file:\n",
    "    sklearn_task_descriptions = json.load(data_file)\n",
    "sklearn_task_ids = []\n",
    "for _,task in sklearn_task_descriptions.items():\n",
    "    sklearn_task_ids.append(task['task']['task_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The following code was run on Brown CCV enironment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the run descriptions for all weka runs (26 hours)\n",
    "weka_run_descriptions = {}\n",
    "for flow,runs in weka_runs_info.items():\n",
    "    for run in runs['runs']['run']:\n",
    "        if str(run['task_id']) in sklearn_task_ids:\n",
    "            run_id = run['run_id']\n",
    "            run_description = get(\"https://www.openml.org/api/v1/json/run/\" + str(run_id) + \"?api_key=\" + api_key).json()\n",
    "            weka_run_descriptions[run_id] = run_description\n",
    "            \n",
    "# with open('OpenML_Data/weka_run_descriptions.json', 'w') as outfile:\n",
    "#     json.dump(weka_run_descriptions, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all weka primitives for each run\n",
    "flows_per_run = {}\n",
    "for run_id,run_description in weka_run_descriptions.items():\n",
    "    flow_id = run_description['run']['flow_id']\n",
    "    flow_names = []\n",
    "    flow_description = weka_flow_descriptions[flow_id]['flow']\n",
    "    name = flow_description['name']\n",
    "    flow_names.append(name)\n",
    "    flows_per_run[run_id] = flow_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of times each weka flow is run\n",
    "flow_names = {}\n",
    "for run,flows in flows_per_run.items():\n",
    "    for flow in flows:\n",
    "        if flow in flow_names:\n",
    "            flow_names[flow] += 1\n",
    "        else:\n",
    "            flow_names[flow] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the adjusted average accuracy (flow accuracy minus mean task accuracy) for all weka flows\n",
    "weka_flow_accuracies = {}\n",
    "for run_id, run_description in weka_run_descriptions.items():\n",
    "    for metric in run_description['run']['output_data']['evaluation']:\n",
    "        if metric['name'] == 'predictive_accuracy':\n",
    "            accuracy = float(metric['value'])\n",
    "            try:\n",
    "                avg_task_acc = task_accuracies[run_description['run']['task_id']]\n",
    "                adjusted_accuracy = (accuracy - avg_task_acc)/avg_task_acc\n",
    "                for flow in flows_per_run[run_id]:\n",
    "                    if flow in weka_flow_accuracies:\n",
    "                        weka_flow_accuracies[flow].append(adjusted_accuracy)\n",
    "                    else:\n",
    "                        weka_flow_accuracies[flow] = [adjusted_accuracy]\n",
    "                break\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 128 ms\n"
     ]
    }
   ],
   "source": [
    "# Read in weka flow accuracies if not already in the environment\n",
    "with open('OpenML_Data/weka_flow_accuracies.json') as data_file:\n",
    "    weka_flow_accuracies = json.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.69 s\n"
     ]
    }
   ],
   "source": [
    "# Create dataframe of average weka flow adjusted accuracies\n",
    "mean_flow_accuracies = pd.DataFrame(columns=['Name', 'Adj_Accuracy', 'Count', 'sd'])\n",
    "for flow,accuracies in weka_flow_accuracies.items():\n",
    "    mean_flow_accuracies = mean_flow_accuracies.append(pd.DataFrame([[flow,np.asarray(accuracies).astype(np.float).mean(), len(accuracies), np.asarray(accuracies).astype(np.float).std()]], columns=['Name', 'Adj_Accuracy', 'Count', 'sd']))\n",
    "mean_flow_accuracies = mean_flow_accuracies[mean_flow_accuracies['Count'] >= 1000]\n",
    "\n",
    "# mean_flow_accuracies.to_csv('OpenML_Data/weka_mean_flow_accuracies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7min 15s\n"
     ]
    }
   ],
   "source": [
    "# Reformatting flow accuracies for plotting (9 minutes)\n",
    "flow_accuracies_df = pd.DataFrame(columns=['Name', 'Adj_Accuracy'])\n",
    "for flow,accuracies in weka_flow_accuracies.items():\n",
    "    for accuracy in accuracies:\n",
    "        flow_accuracies_df = flow_accuracies_df.append(pd.DataFrame([[flow,accuracy]], columns=['Name', 'Adj_Accuracy']))\n",
    "flow_accuracies_df = flow_accuracies_df[flow_accuracies_df.groupby('Name').Adj_Accuracy.transform(len) > 1000]\n",
    "\n",
    "# flow_accuracies_df.to_csv(\"OpenML_Data/weka_flow_accuracies_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dataset download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 66.7 ms\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "with open('OpenML_Data/sklearn_task_descriptions.json') as data_file:\n",
    "    sklearn_task_descriptions = json.load(data_file)  \n",
    "with open('OpenML_Data/sklearn_data_set_descriptions.json') as data_file:\n",
    "    sklearn_data_set_descriptions = json.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 8.11 ms\n"
     ]
    }
   ],
   "source": [
    "# Get all sklearn data set ids and file ids\n",
    "data_set_ids = []\n",
    "data_set_file_ids = {}\n",
    "for task_id,task_description in sklearn_task_descriptions.items():\n",
    "    data_set_id = task_description['task']['input'][0]['data_set']['data_set_id']\n",
    "    data_set_file_id = sklearn_data_set_descriptions[data_set_id]['data_set_description']['file_id']\n",
    "    data_set_ids.append(data_set_id)\n",
    "    data_set_file_ids[data_set_id] = data_set_file_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download all sklearn dataset qualities and features from OpenML (run on Brown CCV enviornment, takes very long)\n",
    "num_data_sets = len(data_set_ids)\n",
    "sklearn_data_set_features = {}\n",
    "sklearn_data_set_qualities = {}\n",
    "for data_set_id in data_set_ids:\n",
    "    url='https://www.openml.org/data/get_csv/' + str(data_set_file_ids[data_set_id])\n",
    "    response = get(url).content\n",
    "    with open(\"Data/\" + str(data_set_id) + \".csv\", 'wb') as f:\n",
    "        f.write(response)\n",
    "    qualities = get(\"https://www.openml.org/api/v1/json/data/qualities/\" + str(data_set_id) + \"?api_key=\" + api_key).json()\n",
    "    try:\n",
    "        features = get(\"https://www.openml.org/api/v1/json/data/features/\" + str(data_set_id) + \"?api_key=\" + api_key).json()\n",
    "    except:\n",
    "        features = {}\n",
    "        print(\"Failed on data set id =\" + str(data_set_id))\n",
    "    sklearn_data_set_qualities[data_set_id] = qualities\n",
    "    sklearn_data_set_features[data_set_id] = features\n",
    "    \n",
    "# with open('OpenML_Data/sklearn_data_set_qualities.json', 'w') as outfile:\n",
    "#     json.dump(sklearn_data_set_qualities, outfile)\n",
    "\n",
    "# with open('OpenML_Data/sklearn_data_set_features.json', 'w') as outfile:\n",
    "#     json.dump(sklearn_data_set_features, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
